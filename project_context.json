{
  "timestamp": "2025-08-09T14:27:05.468314",
  "base_dir": "C:\\Ariel\\integhra\\pomp.ia",
  "file_structure": {
    "num_files": 8,
    "num_dirs": 3,
    "files": [
      ".dockerignore",
      ".gitignore",
      "docker-compose.yml",
      "Dockerfile",
      "poetry.lock",
      "project_context.json",
      "pyproject.toml",
      "README.md"
    ],
    "dirs": {
      "actions": {
        "num_files": 1,
        "num_dirs": 0,
        "files": [
          "actions.py"
        ],
        "dirs": {}
      },
      "bot": {
        "num_files": 5,
        "num_dirs": 3,
        "files": [
          "config.yml",
          "domain.yml",
          "endpoints.yml",
          "logging.yml",
          "main.py"
        ],
        "dirs": {
          "data": {
            "num_files": 9,
            "num_dirs": 1,
            "files": [
              "category.csv",
              "enterprise.csv",
              "nlu.yml",
              "offer.csv",
              "offer_product.csv",
              "product.csv",
              "rules.yml",
              "stories.yml",
              "synonyms.yml"
            ],
            "dirs": {
              "regex": {
                "num_files": 2,
                "num_dirs": 0,
                "files": [
                  "fecha.txt",
                  "moneda.txt"
                ],
                "dirs": {}
              }
            }
          },
          "entrenador": {
            "num_files": 8,
            "num_dirs": 0,
            "files": [
              "entidades.py",
              "exporter.py",
              "generator.py",
              "lookup.py",
              "paraphraser.py",
              "templates.py",
              "train.py",
              "utils.py"
            ],
            "dirs": {}
          },
          "models": {
            "num_files": 1,
            "num_dirs": 0,
            "files": [
              "20250808-112500-patient-monitor.tar.gz"
            ],
            "dirs": {}
          }
        }
      },
      "scripts": {
        "num_files": 3,
        "num_dirs": 0,
        "files": [
          "manage.py",
          "savecontext.py",
          "__init__.py"
        ],
        "dirs": {}
      }
    }
  },
  "poetry_dependencies": {
    "general": {
      "python": ">=3.9.0,<3.11",
      "make": "^0.1.6.post2"
    },
    "groups": {
      "dev": {
        "tomli": "^2.2.1"
      },
      "bot": {
        "pandas": ">=1.5.3,<2.0.0",
        "transformers": ">=4.54.1,<5.0.0",
        "torch": ">=2.7.1,<3.0.0",
        "sentencepiece": ">=0.2.0,<0.3.0",
        "sacremoses": ">=0.1.1,<0.2.0",
        "unidecode": ">=1.4.0,<2.0.0",
        "rasa-sdk": "^3.6.1",
        "rasa": "^3.6.21"
      },
      "actions": {
        "rasa-sdk": "^3.6.1",
        "rasa": "^3.6.21"
      }
    }
  },
  "docker_info": {
    "docker_compose": {
      "version": "3.9",
      "services": {
        "rasa": {
          "build": {
            "context": ".",
            "target": "rasa"
          },
          "container_name": "rasa_server",
          "volumes": [
            "./bot/data:/app/bot/data",
            "./bot/models:/app/bot/models"
          ],
          "ports": [
            "5005:5005"
          ],
          "depends_on": [
            "action_server"
          ]
        },
        "action_server": {
          "build": {
            "context": ".",
            "target": "actions"
          },
          "container_name": "rasa_actions",
          "volumes": [
            "./actions:/app/actions"
          ],
          "ports": [
            "5055:5055"
          ]
        },
        "trainer": {
          "build": {
            "context": ".",
            "target": "rasa"
          },
          "container_name": "rasa_trainer",
          "volumes": [
            "./bot/data:/app/bot/data",
            "./bot/models:/app/bot/models"
          ],
          "entrypoint": [
            "poetry",
            "run",
            "python",
            "entrenador/train.py"
          ]
        }
      }
    },
    "dockerfiles": {
      "Dockerfile": "# ----------------------\n# Etapa base\n# ----------------------\nFROM python:3.10-slim AS base\n\nWORKDIR /app\n\n# Evitar prompts y mejorar cacheo\nENV POETRY_VIRTUALENVS_CREATE=false \\\n    PIP_DISABLE_PIP_VERSION_CHECK=on \\\n    PIP_NO_CACHE_DIR=on\n\n# Copiamos dependencias primero para aprovechar cache\nCOPY pyproject.toml poetry.lock ./\nRUN pip install --upgrade pip && pip install poetry\n\n# ----------------------\n# Etapa Bot (Rasa)\n# ----------------------\nFROM base AS rasa\nRUN poetry install --only bot --no-root --no-dev\nCOPY bot /app/bot\nWORKDIR /app/bot\nCMD [\"poetry\", \"run\", \"rasa\", \"run\", \"--enable-api\", \"--cors\", \"*\"]\n\n# ----------------------\n# Etapa Actions\n# ----------------------\nFROM base AS actions\nRUN poetry install --only actions --no-root --no-dev\nCOPY actions /app/actions\nWORKDIR /app/actions\nCMD [\"poetry\", \"run\", \"rasa\", \"run\", \"actions\"]\n"
    }
  },
  "manage_py": null,
  "scripts": {
    "manage.py": "#!/usr/bin/env python3\n\"\"\"\nGestor de tareas para PompIA\n----------------------------\nUso:\n    python manage.py <comando>\n\nComandos disponibles:\n    up          → Levanta los contenedores\n    down        → Baja los contenedores\n    build       → Construye imágenes Docker\n    restart     → Reinicia el sistema con build\n    logs        → Muestra logs en vivo\n    shell       → Abre bash dentro del contenedor Rasa\n    clean       → Limpieza de contenedores huérfanos\n    prune       → Limpieza total de Docker (¡cuidado!)\n    clean-all   → Limpieza profunda\n    reset       → Borra todo y reconstruye\n    train       → Entrena el bot\n    run         → Ejecuta bot + acciones\n    snapshot    → Guarda contexto del proyecto\n    help        → Muestra esta ayuda\n\"\"\"\n\nimport subprocess\nimport sys\nimport os\n\n# Forzar UTF-8 para evitar errores con emojis en Windows\nsys.stdout.reconfigure(encoding='utf-8')\n\n# ====================\n# Funciones utilitarias\n# ====================\ndef run(cmd, shell=False):\n    \"\"\"Ejecuta un comando y muestra su salida en tiempo real.\"\"\"\n    pretty_cmd = ' '.join(cmd) if isinstance(cmd, list) else cmd\n    print(f\"⚙️  Ejecutando: {pretty_cmd}\")\n    try:\n        subprocess.run(cmd, shell=shell, check=True)\n    except subprocess.CalledProcessError as e:\n        print(f\"❌ Error ejecutando: {pretty_cmd}\")\n        sys.exit(e.returncode)\n\n# ====================\n# Comandos del gestor\n# ====================\ndef up():\n    \"\"\"Levanta los contenedores\"\"\"\n    run([\"docker\", \"compose\", \"up\"])\n\ndef down():\n    \"\"\"Baja los contenedores\"\"\"\n    run([\"docker\", \"compose\", \"down\"])\n\ndef build():\n    \"\"\"Construye las imágenes Docker\"\"\"\n    run([\"docker\", \"compose\", \"build\"])\n\ndef restart():\n    \"\"\"Reinicia el sistema con build\"\"\"\n    run(\"docker compose down && docker compose up --build\", shell=True)\n\ndef logs():\n    \"\"\"Muestra logs en tiempo real\"\"\"\n    run([\"docker\", \"compose\", \"logs\", \"-f\"])\n\ndef shell_():\n    \"\"\"Abre una shell dentro del contenedor Rasa\"\"\"\n    run([\"docker\", \"compose\", \"exec\", \"rasa\", \"bash\"])\n\ndef clean():\n    \"\"\"Limpia contenedores y volúmenes huérfanos\"\"\"\n    run([\"docker\", \"compose\", \"down\", \"--volumes\", \"--remove-orphans\"])\n\ndef prune():\n    \"\"\"Limpieza total de Docker (cuidado)\"\"\"\n    run([\"docker\", \"system\", \"prune\", \"-af\", \"--volumes\"])\n\ndef clean_all():\n    \"\"\"Limpieza profunda: contenedores, imágenes, volúmenes y redes\"\"\"\n    run([\"docker\", \"container\", \"prune\", \"-f\"])\n    run([\"docker\", \"image\", \"prune\", \"-af\"])\n    run([\"docker\", \"volume\", \"prune\", \"-f\"])\n    run([\"docker\", \"network\", \"prune\", \"-f\"])\n\ndef reset():\n    \"\"\"Borra todo, reconstruye y levanta el sistema\"\"\"\n    clean()\n    build()\n    up()\n\ndef train():\n    \"\"\"Entrena el bot dentro del contenedor\"\"\"\n    run([\"docker\", \"compose\", \"exec\", \"rasa\", \"rasa\", \"train\"])\n\ndef run_agent():\n    \"\"\"Ejecuta bot y acciones juntas\"\"\"\n    run([\"docker\", \"compose\", \"up\", \"rasa\", \"actions\"])\n\ndef snapshot():\n    \"\"\"Guarda contexto del proyecto\"\"\"\n    python_exe = sys.executable\n    ...",
    "savecontext.py": "import os\nimport json\nimport subprocess\nfrom pathlib import Path\nfrom datetime import datetime\nimport sys\nsys.stdout.reconfigure(encoding='utf-8')\nimport tomli\nimport yaml\n\nBASE_DIR = Path.cwd()\nCONTEXT_FILE = BASE_DIR / \"project_context.json\"\n\ndef get_file_structure_summary(base_dir, max_depth=3):\n    \"\"\"Recorre la estructura de archivos hasta max_depth y devuelve un árbol resumido.\"\"\"\n    def helper(path, depth):\n        if depth > max_depth:\n            return {\"note\": \"max depth reached\"}\n        try:\n            files = [\n                f for f in os.listdir(path)\n                if os.path.isfile(os.path.join(path, f)) and not f.endswith('.pyc')\n            ]\n            dirs = [\n                d for d in os.listdir(path)\n                if os.path.isdir(os.path.join(path, d))\n                and d != '__pycache__'\n                and not d.startswith('.git')\n            ]\n            return {\n                \"num_files\": len(files),\n                \"num_dirs\": len(dirs),\n                \"files\": files,\n                \"dirs\": {d: helper(os.path.join(path, d), depth+1) for d in dirs}\n            }\n        except Exception:\n            return {\"error\": \"no access\"}\n    return helper(base_dir, 0)\n\ndef get_poetry_groups_dependencies(pyproject_path):\n    \"\"\"Lee las dependencias generales y por grupos desde pyproject.toml.\"\"\"\n    try:\n        with open(pyproject_path, \"rb\") as f:\n            data = tomli.load(f)\n        tool_poetry = data.get(\"tool\", {}).get(\"poetry\", {})\n        groups = tool_poetry.get(\"group\", {})\n\n        groups_deps = {\n            group_name: group_data.get(\"dependencies\", {})\n            for group_name, group_data in groups.items()\n        }\n        general_deps = tool_poetry.get(\"dependencies\", {})\n\n        return {\"general\": general_deps, \"groups\": groups_deps}\n    except Exception as e:\n        return {\"error\": f\"No se pudo leer pyproject.toml: {e}\"}\n\ndef read_file_if_exists(path, max_chars=3000):\n    \"\"\"Lee un archivo si existe, recortando a max_chars para evitar sobrecarga.\"\"\"\n    p = Path(path)\n    if p.exists():\n        text = p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n        return text[:max_chars] + (\"...\" if len(text) > max_chars else \"\")\n    return None\n\ndef get_docker_info():\n    \"\"\"Extrae configuración de docker-compose.yml y Dockerfiles.\"\"\"\n    info = {}\n    docker_compose_path = BASE_DIR / \"docker-compose.yml\"\n    if docker_compose_path.exists():\n        try:\n            with open(docker_compose_path, \"r\", encoding=\"utf-8\") as f:\n                info[\"docker_compose\"] = yaml.safe_load(f)\n        except Exception as e:\n            info[\"docker_compose_error\"] = str(e)\n    # Buscar Dockerfiles\n    dockerfiles = list(BASE_DIR.glob(\"Dockerfile*\"))\n    dockerfile_contents = {}\n    for df in dockerfiles:\n        dockerfile_contents[df.name] = read_file_if_exists(df, max_chars=3000)\n    if dockerfile_contents:\n        info[\"dockerfiles\"] = dockerfile_contents\n    return info\n\ndef get_git_info():\n    \"\"\"Devu...",
    "__init__.py": ""
  },
  "readme_excerpt": "# 🤖 PompIA – Sistema de Asistente Virtual Inteligente\n\n**PompIA** es un sistema modular de asistente virtual construido con **Rasa** y **Python**, que permite la gestión, entrenamiento y ejecución de un bot conversacional inteligente. Está diseñado para ser escalable, mantenible y fácilmente desplegable mediante contenedores Docker.\n\n> 💡 Este repositorio central (`pomp.ia`) organiza y orquesta los distintos módulos (bot y actions), cada uno ejecutado en su propio contenedor.\n\n---\n\n## 🧱 Estructura del Proyecto\n\n```\npomp.ia/\n│\n│\n├── bot/                # Proyecto principal del chatbot\n│   ├── data/           # NLU y ejemplos de conversación\n│   ├── models/         # Modelos entrenados por Rasa\n│   ├── entrenador/     # Lógica de entrenamiento (opcional)\n│   ├── config.yml      # Configuración del pipeline de Rasa\n│   ├── domain.yml      # Intents, entidades, acciones, respuestas\n│   ├── endpoints.yml   # Configuración de endpoints\n│   ├── pyproject.toml  # Dependencias con Poetry\n│   └── poetry.lock\n│\n├── actions/            # Acciones personalizadas (custom actions)\n│   ├── actions.py      # Acciones en Python\n│   ├── pyproject.toml\n│   └── poetry.lock\n│\n├── docker-compose.yml  # Orquestación de servicios\n├── Dockerfile.rasa     # Imagen del servicio del bot\n├── Dockerfile.actions  # Imagen del servicio de acciones\n├── .dockerignore       # Archivos ignorados en el build\n└── README.md           # Este archivo ✨\n```\n\n---\n\n## 🚀 ¿Qué hace este proyecto?\n\n- 🧠 Usa **Rasa** para NLP/NLU: interpreta intenciones, entidades y contexto.\n- 🎯 Implementa **acciones personalizadas** para integrar lógica adicional en Python.\n- 🐳 Usa **Docker** para aislar los entornos de ejecución (bot y actions).\n- 🔁 Es **modular**, cada componente es autocontenible y fácil de mantener.\n- 🛠️ Puede entrenarse, probarse, actualizarse y desplegarse con un solo comando.\n\n---\n\n## ⚙️ Requisitos Previos\n\n- Docker + Docker Compose\n- Python 3.10+ (solo si corrés fuera de Docker)\n- [Poetry](https://python-p..."
}