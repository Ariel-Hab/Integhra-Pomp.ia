{
  "timestamp": "2025-08-09T14:27:05.468314",
  "base_dir": "C:\\Ariel\\integhra\\pomp.ia",
  "file_structure": {
    "num_files": 8,
    "num_dirs": 3,
    "files": [
      ".dockerignore",
      ".gitignore",
      "docker-compose.yml",
      "Dockerfile",
      "poetry.lock",
      "project_context.json",
      "pyproject.toml",
      "README.md"
    ],
    "dirs": {
      "actions": {
        "num_files": 1,
        "num_dirs": 0,
        "files": [
          "actions.py"
        ],
        "dirs": {}
      },
      "bot": {
        "num_files": 5,
        "num_dirs": 3,
        "files": [
          "config.yml",
          "domain.yml",
          "endpoints.yml",
          "logging.yml",
          "main.py"
        ],
        "dirs": {
          "data": {
            "num_files": 9,
            "num_dirs": 1,
            "files": [
              "category.csv",
              "enterprise.csv",
              "nlu.yml",
              "offer.csv",
              "offer_product.csv",
              "product.csv",
              "rules.yml",
              "stories.yml",
              "synonyms.yml"
            ],
            "dirs": {
              "regex": {
                "num_files": 2,
                "num_dirs": 0,
                "files": [
                  "fecha.txt",
                  "moneda.txt"
                ],
                "dirs": {}
              }
            }
          },
          "entrenador": {
            "num_files": 8,
            "num_dirs": 0,
            "files": [
              "entidades.py",
              "exporter.py",
              "generator.py",
              "lookup.py",
              "paraphraser.py",
              "templates.py",
              "train.py",
              "utils.py"
            ],
            "dirs": {}
          },
          "models": {
            "num_files": 1,
            "num_dirs": 0,
            "files": [
              "20250808-112500-patient-monitor.tar.gz"
            ],
            "dirs": {}
          }
        }
      },
      "scripts": {
        "num_files": 3,
        "num_dirs": 0,
        "files": [
          "manage.py",
          "savecontext.py",
          "__init__.py"
        ],
        "dirs": {}
      }
    }
  },
  "poetry_dependencies": {
    "general": {
      "python": ">=3.9.0,<3.11",
      "make": "^0.1.6.post2"
    },
    "groups": {
      "dev": {
        "tomli": "^2.2.1"
      },
      "bot": {
        "pandas": ">=1.5.3,<2.0.0",
        "transformers": ">=4.54.1,<5.0.0",
        "torch": ">=2.7.1,<3.0.0",
        "sentencepiece": ">=0.2.0,<0.3.0",
        "sacremoses": ">=0.1.1,<0.2.0",
        "unidecode": ">=1.4.0,<2.0.0",
        "rasa-sdk": "^3.6.1",
        "rasa": "^3.6.21"
      },
      "actions": {
        "rasa-sdk": "^3.6.1",
        "rasa": "^3.6.21"
      }
    }
  },
  "docker_info": {
    "docker_compose": {
      "version": "3.9",
      "services": {
        "rasa": {
          "build": {
            "context": ".",
            "target": "rasa"
          },
          "container_name": "rasa_server",
          "volumes": [
            "./bot/data:/app/bot/data",
            "./bot/models:/app/bot/models"
          ],
          "ports": [
            "5005:5005"
          ],
          "depends_on": [
            "action_server"
          ]
        },
        "action_server": {
          "build": {
            "context": ".",
            "target": "actions"
          },
          "container_name": "rasa_actions",
          "volumes": [
            "./actions:/app/actions"
          ],
          "ports": [
            "5055:5055"
          ]
        },
        "trainer": {
          "build": {
            "context": ".",
            "target": "rasa"
          },
          "container_name": "rasa_trainer",
          "volumes": [
            "./bot/data:/app/bot/data",
            "./bot/models:/app/bot/models"
          ],
          "entrypoint": [
            "poetry",
            "run",
            "python",
            "entrenador/train.py"
          ]
        }
      }
    },
    "dockerfiles": {
      "Dockerfile": "# ----------------------\n# Etapa base\n# ----------------------\nFROM python:3.10-slim AS base\n\nWORKDIR /app\n\n# Evitar prompts y mejorar cacheo\nENV POETRY_VIRTUALENVS_CREATE=false \\\n    PIP_DISABLE_PIP_VERSION_CHECK=on \\\n    PIP_NO_CACHE_DIR=on\n\n# Copiamos dependencias primero para aprovechar cache\nCOPY pyproject.toml poetry.lock ./\nRUN pip install --upgrade pip && pip install poetry\n\n# ----------------------\n# Etapa Bot (Rasa)\n# ----------------------\nFROM base AS rasa\nRUN poetry install --only bot --no-root --no-dev\nCOPY bot /app/bot\nWORKDIR /app/bot\nCMD [\"poetry\", \"run\", \"rasa\", \"run\", \"--enable-api\", \"--cors\", \"*\"]\n\n# ----------------------\n# Etapa Actions\n# ----------------------\nFROM base AS actions\nRUN poetry install --only actions --no-root --no-dev\nCOPY actions /app/actions\nWORKDIR /app/actions\nCMD [\"poetry\", \"run\", \"rasa\", \"run\", \"actions\"]\n"
    }
  },
  "manage_py": null,
  "scripts": {
    "manage.py": "#!/usr/bin/env python3\n\"\"\"\nGestor de tareas para PompIA\n----------------------------\nUso:\n    python manage.py <comando>\n\nComandos disponibles:\n    up          â†’ Levanta los contenedores\n    down        â†’ Baja los contenedores\n    build       â†’ Construye imÃ¡genes Docker\n    restart     â†’ Reinicia el sistema con build\n    logs        â†’ Muestra logs en vivo\n    shell       â†’ Abre bash dentro del contenedor Rasa\n    clean       â†’ Limpieza de contenedores huÃ©rfanos\n    prune       â†’ Limpieza total de Docker (Â¡cuidado!)\n    clean-all   â†’ Limpieza profunda\n    reset       â†’ Borra todo y reconstruye\n    train       â†’ Entrena el bot\n    run         â†’ Ejecuta bot + acciones\n    snapshot    â†’ Guarda contexto del proyecto\n    help        â†’ Muestra esta ayuda\n\"\"\"\n\nimport subprocess\nimport sys\nimport os\n\n# Forzar UTF-8 para evitar errores con emojis en Windows\nsys.stdout.reconfigure(encoding='utf-8')\n\n# ====================\n# Funciones utilitarias\n# ====================\ndef run(cmd, shell=False):\n    \"\"\"Ejecuta un comando y muestra su salida en tiempo real.\"\"\"\n    pretty_cmd = ' '.join(cmd) if isinstance(cmd, list) else cmd\n    print(f\"âš™ï¸  Ejecutando: {pretty_cmd}\")\n    try:\n        subprocess.run(cmd, shell=shell, check=True)\n    except subprocess.CalledProcessError as e:\n        print(f\"âŒ Error ejecutando: {pretty_cmd}\")\n        sys.exit(e.returncode)\n\n# ====================\n# Comandos del gestor\n# ====================\ndef up():\n    \"\"\"Levanta los contenedores\"\"\"\n    run([\"docker\", \"compose\", \"up\"])\n\ndef down():\n    \"\"\"Baja los contenedores\"\"\"\n    run([\"docker\", \"compose\", \"down\"])\n\ndef build():\n    \"\"\"Construye las imÃ¡genes Docker\"\"\"\n    run([\"docker\", \"compose\", \"build\"])\n\ndef restart():\n    \"\"\"Reinicia el sistema con build\"\"\"\n    run(\"docker compose down && docker compose up --build\", shell=True)\n\ndef logs():\n    \"\"\"Muestra logs en tiempo real\"\"\"\n    run([\"docker\", \"compose\", \"logs\", \"-f\"])\n\ndef shell_():\n    \"\"\"Abre una shell dentro del contenedor Rasa\"\"\"\n    run([\"docker\", \"compose\", \"exec\", \"rasa\", \"bash\"])\n\ndef clean():\n    \"\"\"Limpia contenedores y volÃºmenes huÃ©rfanos\"\"\"\n    run([\"docker\", \"compose\", \"down\", \"--volumes\", \"--remove-orphans\"])\n\ndef prune():\n    \"\"\"Limpieza total de Docker (cuidado)\"\"\"\n    run([\"docker\", \"system\", \"prune\", \"-af\", \"--volumes\"])\n\ndef clean_all():\n    \"\"\"Limpieza profunda: contenedores, imÃ¡genes, volÃºmenes y redes\"\"\"\n    run([\"docker\", \"container\", \"prune\", \"-f\"])\n    run([\"docker\", \"image\", \"prune\", \"-af\"])\n    run([\"docker\", \"volume\", \"prune\", \"-f\"])\n    run([\"docker\", \"network\", \"prune\", \"-f\"])\n\ndef reset():\n    \"\"\"Borra todo, reconstruye y levanta el sistema\"\"\"\n    clean()\n    build()\n    up()\n\ndef train():\n    \"\"\"Entrena el bot dentro del contenedor\"\"\"\n    run([\"docker\", \"compose\", \"exec\", \"rasa\", \"rasa\", \"train\"])\n\ndef run_agent():\n    \"\"\"Ejecuta bot y acciones juntas\"\"\"\n    run([\"docker\", \"compose\", \"up\", \"rasa\", \"actions\"])\n\ndef snapshot():\n    \"\"\"Guarda contexto del proyecto\"\"\"\n    python_exe = sys.executable\n    ...",
    "savecontext.py": "import os\nimport json\nimport subprocess\nfrom pathlib import Path\nfrom datetime import datetime\nimport sys\nsys.stdout.reconfigure(encoding='utf-8')\nimport tomli\nimport yaml\n\nBASE_DIR = Path.cwd()\nCONTEXT_FILE = BASE_DIR / \"project_context.json\"\n\ndef get_file_structure_summary(base_dir, max_depth=3):\n    \"\"\"Recorre la estructura de archivos hasta max_depth y devuelve un Ã¡rbol resumido.\"\"\"\n    def helper(path, depth):\n        if depth > max_depth:\n            return {\"note\": \"max depth reached\"}\n        try:\n            files = [\n                f for f in os.listdir(path)\n                if os.path.isfile(os.path.join(path, f)) and not f.endswith('.pyc')\n            ]\n            dirs = [\n                d for d in os.listdir(path)\n                if os.path.isdir(os.path.join(path, d))\n                and d != '__pycache__'\n                and not d.startswith('.git')\n            ]\n            return {\n                \"num_files\": len(files),\n                \"num_dirs\": len(dirs),\n                \"files\": files,\n                \"dirs\": {d: helper(os.path.join(path, d), depth+1) for d in dirs}\n            }\n        except Exception:\n            return {\"error\": \"no access\"}\n    return helper(base_dir, 0)\n\ndef get_poetry_groups_dependencies(pyproject_path):\n    \"\"\"Lee las dependencias generales y por grupos desde pyproject.toml.\"\"\"\n    try:\n        with open(pyproject_path, \"rb\") as f:\n            data = tomli.load(f)\n        tool_poetry = data.get(\"tool\", {}).get(\"poetry\", {})\n        groups = tool_poetry.get(\"group\", {})\n\n        groups_deps = {\n            group_name: group_data.get(\"dependencies\", {})\n            for group_name, group_data in groups.items()\n        }\n        general_deps = tool_poetry.get(\"dependencies\", {})\n\n        return {\"general\": general_deps, \"groups\": groups_deps}\n    except Exception as e:\n        return {\"error\": f\"No se pudo leer pyproject.toml: {e}\"}\n\ndef read_file_if_exists(path, max_chars=3000):\n    \"\"\"Lee un archivo si existe, recortando a max_chars para evitar sobrecarga.\"\"\"\n    p = Path(path)\n    if p.exists():\n        text = p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n        return text[:max_chars] + (\"...\" if len(text) > max_chars else \"\")\n    return None\n\ndef get_docker_info():\n    \"\"\"Extrae configuraciÃ³n de docker-compose.yml y Dockerfiles.\"\"\"\n    info = {}\n    docker_compose_path = BASE_DIR / \"docker-compose.yml\"\n    if docker_compose_path.exists():\n        try:\n            with open(docker_compose_path, \"r\", encoding=\"utf-8\") as f:\n                info[\"docker_compose\"] = yaml.safe_load(f)\n        except Exception as e:\n            info[\"docker_compose_error\"] = str(e)\n    # Buscar Dockerfiles\n    dockerfiles = list(BASE_DIR.glob(\"Dockerfile*\"))\n    dockerfile_contents = {}\n    for df in dockerfiles:\n        dockerfile_contents[df.name] = read_file_if_exists(df, max_chars=3000)\n    if dockerfile_contents:\n        info[\"dockerfiles\"] = dockerfile_contents\n    return info\n\ndef get_git_info():\n    \"\"\"Devu...",
    "__init__.py": ""
  },
  "readme_excerpt": "# ğŸ¤– PompIA â€“ Sistema de Asistente Virtual Inteligente\n\n**PompIA** es un sistema modular de asistente virtual construido con **Rasa** y **Python**, que permite la gestiÃ³n, entrenamiento y ejecuciÃ³n de un bot conversacional inteligente. EstÃ¡ diseÃ±ado para ser escalable, mantenible y fÃ¡cilmente desplegable mediante contenedores Docker.\n\n> ğŸ’¡ Este repositorio central (`pomp.ia`) organiza y orquesta los distintos mÃ³dulos (bot y actions), cada uno ejecutado en su propio contenedor.\n\n---\n\n## ğŸ§± Estructura del Proyecto\n\n```\npomp.ia/\nâ”‚\nâ”‚\nâ”œâ”€â”€ bot/                # Proyecto principal del chatbot\nâ”‚   â”œâ”€â”€ data/           # NLU y ejemplos de conversaciÃ³n\nâ”‚   â”œâ”€â”€ models/         # Modelos entrenados por Rasa\nâ”‚   â”œâ”€â”€ entrenador/     # LÃ³gica de entrenamiento (opcional)\nâ”‚   â”œâ”€â”€ config.yml      # ConfiguraciÃ³n del pipeline de Rasa\nâ”‚   â”œâ”€â”€ domain.yml      # Intents, entidades, acciones, respuestas\nâ”‚   â”œâ”€â”€ endpoints.yml   # ConfiguraciÃ³n de endpoints\nâ”‚   â”œâ”€â”€ pyproject.toml  # Dependencias con Poetry\nâ”‚   â””â”€â”€ poetry.lock\nâ”‚\nâ”œâ”€â”€ actions/            # Acciones personalizadas (custom actions)\nâ”‚   â”œâ”€â”€ actions.py      # Acciones en Python\nâ”‚   â”œâ”€â”€ pyproject.toml\nâ”‚   â””â”€â”€ poetry.lock\nâ”‚\nâ”œâ”€â”€ docker-compose.yml  # OrquestaciÃ³n de servicios\nâ”œâ”€â”€ Dockerfile.rasa     # Imagen del servicio del bot\nâ”œâ”€â”€ Dockerfile.actions  # Imagen del servicio de acciones\nâ”œâ”€â”€ .dockerignore       # Archivos ignorados en el build\nâ””â”€â”€ README.md           # Este archivo âœ¨\n```\n\n---\n\n## ğŸš€ Â¿QuÃ© hace este proyecto?\n\n- ğŸ§  Usa **Rasa** para NLP/NLU: interpreta intenciones, entidades y contexto.\n- ğŸ¯ Implementa **acciones personalizadas** para integrar lÃ³gica adicional en Python.\n- ğŸ³ Usa **Docker** para aislar los entornos de ejecuciÃ³n (bot y actions).\n- ğŸ” Es **modular**, cada componente es autocontenible y fÃ¡cil de mantener.\n- ğŸ› ï¸ Puede entrenarse, probarse, actualizarse y desplegarse con un solo comando.\n\n---\n\n## âš™ï¸ Requisitos Previos\n\n- Docker + Docker Compose\n- Python 3.10+ (solo si corrÃ©s fuera de Docker)\n- [Poetry](https://python-p..."
}